## PySpark Components and API Utilized

-> spark.read.csv/json/parquet(path) or spark.read.format(csv/json/....).load(path) <br>
-> display() funcion  <br>
-> printSchema() <br>
-> withColumn() function : to cast datatype, to create a new column <br>
-> withcolumnRenamed(oldname, newname) <br>
-> UDF in spark <br>
-> drop(column name) <br>
-> dropna(subset=list of columns) <br>
-> spark.write.mode().option().csv/json/parquet/(path)  <br>
-> filter() or where()
-> orderBy()
-> .columns
-> select()
-> aggregation functions
